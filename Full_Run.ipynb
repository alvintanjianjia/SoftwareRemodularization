{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import jellyfish\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from zipfile import ZipFile\n",
    "from filecmp import dircmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = 'apache-log4j'\n",
    "project_releases = pd.read_csv('project_links_202.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_name</th>\n",
       "      <th>project_link</th>\n",
       "      <th>revision</th>\n",
       "      <th>version_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZieIony-Carbon</td>\n",
       "      <td>https://github.com/ZieIony/Carbon</td>\n",
       "      <td>567fd84</td>\n",
       "      <td>7.1.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZieIony-Carbon</td>\n",
       "      <td>https://github.com/ZieIony/Carbon</td>\n",
       "      <td>9a343f5</td>\n",
       "      <td>7.1.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZieIony-Carbon</td>\n",
       "      <td>https://github.com/ZieIony/Carbon</td>\n",
       "      <td>a655476</td>\n",
       "      <td>7.1.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZieIony-Carbon</td>\n",
       "      <td>https://github.com/ZieIony/Carbon</td>\n",
       "      <td>ad84a93</td>\n",
       "      <td>7.1.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZieIony-Carbon</td>\n",
       "      <td>https://github.com/ZieIony/Carbon</td>\n",
       "      <td>5fa652f</td>\n",
       "      <td>7.1.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     project_name                       project_link revision version_name\n",
       "0  ZieIony-Carbon  https://github.com/ZieIony/Carbon  567fd84       7.1.84\n",
       "1  ZieIony-Carbon  https://github.com/ZieIony/Carbon  9a343f5       7.1.83\n",
       "2  ZieIony-Carbon  https://github.com/ZieIony/Carbon  a655476       7.1.82\n",
       "3  ZieIony-Carbon  https://github.com/ZieIony/Carbon  ad84a93       7.1.81\n",
       "4  ZieIony-Carbon  https://github.com/ZieIony/Carbon  5fa652f       7.1.80"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_releases.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_name</th>\n",
       "      <th>project_link</th>\n",
       "      <th>revision</th>\n",
       "      <th>version_name</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>apache-log4j</td>\n",
       "      <td>https://github.com/apache/log4j</td>\n",
       "      <td>31d7ec7</td>\n",
       "      <td>8.2.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>apache-log4j</td>\n",
       "      <td>https://github.com/apache/log4j</td>\n",
       "      <td>fcbe46c</td>\n",
       "      <td>8.1.1</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>apache-log4j</td>\n",
       "      <td>https://github.com/apache/log4j</td>\n",
       "      <td>dbe5ed0</td>\n",
       "      <td>8.1.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>apache-log4j</td>\n",
       "      <td>https://github.com/apache/log4j</td>\n",
       "      <td>2ae4746</td>\n",
       "      <td>8.0.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>apache-log4j</td>\n",
       "      <td>https://github.com/apache/log4j</td>\n",
       "      <td>d4c30fc</td>\n",
       "      <td>7.7.2</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>apache-log4j</td>\n",
       "      <td>https://github.com/apache/log4j</td>\n",
       "      <td>5bf96d3</td>\n",
       "      <td>7.7.1</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>apache-log4j</td>\n",
       "      <td>https://github.com/apache/log4j</td>\n",
       "      <td>8c831da</td>\n",
       "      <td>7.7.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>apache-log4j</td>\n",
       "      <td>https://github.com/apache/log4j</td>\n",
       "      <td>719cde9</td>\n",
       "      <td>7.6.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>apache-log4j</td>\n",
       "      <td>https://github.com/apache/log4j</td>\n",
       "      <td>b5bf70b</td>\n",
       "      <td>7.5.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>apache-log4j</td>\n",
       "      <td>https://github.com/apache/log4j</td>\n",
       "      <td>9060ac6</td>\n",
       "      <td>7.4.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081</th>\n",
       "      <td>apache-log4j</td>\n",
       "      <td>https://github.com/apache/log4j</td>\n",
       "      <td>ae0705e</td>\n",
       "      <td>7.3.1</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>apache-log4j</td>\n",
       "      <td>https://github.com/apache/log4j</td>\n",
       "      <td>98a6b3d</td>\n",
       "      <td>7.3.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>apache-log4j</td>\n",
       "      <td>https://github.com/apache/log4j</td>\n",
       "      <td>b2b6438</td>\n",
       "      <td>7.2.1</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>apache-log4j</td>\n",
       "      <td>https://github.com/apache/log4j</td>\n",
       "      <td>bca54ca</td>\n",
       "      <td>7.2.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>apache-log4j</td>\n",
       "      <td>https://github.com/apache/log4j</td>\n",
       "      <td>84c90ad</td>\n",
       "      <td>7.1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>apache-log4j</td>\n",
       "      <td>https://github.com/apache/log4j</td>\n",
       "      <td>68fa249</td>\n",
       "      <td>6.6.6</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>apache-log4j</td>\n",
       "      <td>https://github.com/apache/log4j</td>\n",
       "      <td>d29c3d1</td>\n",
       "      <td>6.6.5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>apache-log4j</td>\n",
       "      <td>https://github.com/apache/log4j</td>\n",
       "      <td>073a1fe</td>\n",
       "      <td>6.6.4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>apache-log4j</td>\n",
       "      <td>https://github.com/apache/log4j</td>\n",
       "      <td>d1e9bbd</td>\n",
       "      <td>6.6.3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>apache-log4j</td>\n",
       "      <td>https://github.com/apache/log4j</td>\n",
       "      <td>df4de29</td>\n",
       "      <td>6.6.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>apache-log4j</td>\n",
       "      <td>https://github.com/apache/log4j</td>\n",
       "      <td>b344167</td>\n",
       "      <td>5.5.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      project_name                     project_link revision version_name  \\\n",
       "1071  apache-log4j  https://github.com/apache/log4j  31d7ec7        8.2.0   \n",
       "1072  apache-log4j  https://github.com/apache/log4j  fcbe46c        8.1.1   \n",
       "1073  apache-log4j  https://github.com/apache/log4j  dbe5ed0        8.1.0   \n",
       "1074  apache-log4j  https://github.com/apache/log4j  2ae4746        8.0.0   \n",
       "1075  apache-log4j  https://github.com/apache/log4j  d4c30fc        7.7.2   \n",
       "1076  apache-log4j  https://github.com/apache/log4j  5bf96d3        7.7.1   \n",
       "1077  apache-log4j  https://github.com/apache/log4j  8c831da        7.7.0   \n",
       "1078  apache-log4j  https://github.com/apache/log4j  719cde9        7.6.0   \n",
       "1079  apache-log4j  https://github.com/apache/log4j  b5bf70b        7.5.0   \n",
       "1080  apache-log4j  https://github.com/apache/log4j  9060ac6        7.4.0   \n",
       "1081  apache-log4j  https://github.com/apache/log4j  ae0705e        7.3.1   \n",
       "1082  apache-log4j  https://github.com/apache/log4j  98a6b3d        7.3.0   \n",
       "1083  apache-log4j  https://github.com/apache/log4j  b2b6438        7.2.1   \n",
       "1084  apache-log4j  https://github.com/apache/log4j  bca54ca        7.2.0   \n",
       "1085  apache-log4j  https://github.com/apache/log4j  84c90ad        7.1.0   \n",
       "1086  apache-log4j  https://github.com/apache/log4j  68fa249        6.6.6   \n",
       "1087  apache-log4j  https://github.com/apache/log4j  d29c3d1        6.6.5   \n",
       "1088  apache-log4j  https://github.com/apache/log4j  073a1fe        6.6.4   \n",
       "1089  apache-log4j  https://github.com/apache/log4j  d1e9bbd        6.6.3   \n",
       "1090  apache-log4j  https://github.com/apache/log4j  df4de29        6.6.2   \n",
       "1091  apache-log4j  https://github.com/apache/log4j  b344167        5.5.5   \n",
       "\n",
       "      rank  \n",
       "1071  21.0  \n",
       "1072  20.0  \n",
       "1073  19.0  \n",
       "1074  18.0  \n",
       "1075  17.0  \n",
       "1076  16.0  \n",
       "1077  15.0  \n",
       "1078  14.0  \n",
       "1079  13.0  \n",
       "1080  12.0  \n",
       "1081  11.0  \n",
       "1082  10.0  \n",
       "1083   9.0  \n",
       "1084   8.0  \n",
       "1085   7.0  \n",
       "1086   6.0  \n",
       "1087   5.0  \n",
       "1088   4.0  \n",
       "1089   3.0  \n",
       "1090   2.0  \n",
       "1091   1.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_project = pd.DataFrame(project_releases[project_releases['project_name'] == project_name])\n",
    "current_project['rank'] = current_project['version_name'].rank()\n",
    "current_project = current_project.sort_values(by=['rank'], ascending=False)\n",
    "current_project.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Download dataset\n",
    "try:\n",
    "    os.mkdir('raw_sourcecode/' + project_name)\n",
    "except:\n",
    "    pass\n",
    "for row in current_project.iterrows():\n",
    "    command = 'cd C:/Users/tanji/Desktop/SoftwareRemodularization/raw_sourcecode/' + project_name +' & mkdir ' + project_name + '_' +row[1]['version_name']\n",
    "    \n",
    "    #print(command)\n",
    "    os.system(command)\n",
    "    \n",
    "    command = 'git clone ' + row[1]['project_link'] +  ' C:/Users/tanji/Desktop/SoftwareRemodularization/raw_sourcecode/' + project_name + '/' + project_name + '_' + row[1]['version_name']\n",
    "    \n",
    "    print(command)\n",
    "    os.system(command)\n",
    "    command = 'cd C:/Users/tanji/Desktop/SoftwareRemodularization/raw_sourcecode/' + project_name + '/' + project_name +'_' + row[1]['version_name'] + ' & git checkout ' + row[1]['revision']\n",
    "    print(command)\n",
    "    os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cd C:/Users/tanji/Desktop/SoftwareRemodularization/depends-0.9.2 & java -jar depends.jar java C:/Users/tanji/Desktop/SoftwareRemodularization/raw_sourcecode/apache-log4j/apache-log4j_8.2.0 ../raw_depends/apache-log4j/apache-log4j_8.2.0\n",
      "cd C:/Users/tanji/Desktop/SoftwareRemodularization/depends-0.9.2 & java -jar depends.jar java C:/Users/tanji/Desktop/SoftwareRemodularization/raw_sourcecode/apache-log4j/apache-log4j_8.1.1 ../raw_depends/apache-log4j/apache-log4j_8.1.1\n",
      "cd C:/Users/tanji/Desktop/SoftwareRemodularization/depends-0.9.2 & java -jar depends.jar java C:/Users/tanji/Desktop/SoftwareRemodularization/raw_sourcecode/apache-log4j/apache-log4j_8.1.0 ../raw_depends/apache-log4j/apache-log4j_8.1.0\n",
      "cd C:/Users/tanji/Desktop/SoftwareRemodularization/depends-0.9.2 & java -jar depends.jar java C:/Users/tanji/Desktop/SoftwareRemodularization/raw_sourcecode/apache-log4j/apache-log4j_8.0.0 ../raw_depends/apache-log4j/apache-log4j_8.0.0\n",
      "cd C:/Users/tanji/Desktop/SoftwareRemodularization/depends-0.9.2 & java -jar depends.jar java C:/Users/tanji/Desktop/SoftwareRemodularization/raw_sourcecode/apache-log4j/apache-log4j_7.7.2 ../raw_depends/apache-log4j/apache-log4j_7.7.2\n",
      "cd C:/Users/tanji/Desktop/SoftwareRemodularization/depends-0.9.2 & java -jar depends.jar java C:/Users/tanji/Desktop/SoftwareRemodularization/raw_sourcecode/apache-log4j/apache-log4j_7.7.1 ../raw_depends/apache-log4j/apache-log4j_7.7.1\n",
      "cd C:/Users/tanji/Desktop/SoftwareRemodularization/depends-0.9.2 & java -jar depends.jar java C:/Users/tanji/Desktop/SoftwareRemodularization/raw_sourcecode/apache-log4j/apache-log4j_7.7.0 ../raw_depends/apache-log4j/apache-log4j_7.7.0\n",
      "cd C:/Users/tanji/Desktop/SoftwareRemodularization/depends-0.9.2 & java -jar depends.jar java C:/Users/tanji/Desktop/SoftwareRemodularization/raw_sourcecode/apache-log4j/apache-log4j_7.6.0 ../raw_depends/apache-log4j/apache-log4j_7.6.0\n",
      "cd C:/Users/tanji/Desktop/SoftwareRemodularization/depends-0.9.2 & java -jar depends.jar java C:/Users/tanji/Desktop/SoftwareRemodularization/raw_sourcecode/apache-log4j/apache-log4j_7.5.0 ../raw_depends/apache-log4j/apache-log4j_7.5.0\n",
      "cd C:/Users/tanji/Desktop/SoftwareRemodularization/depends-0.9.2 & java -jar depends.jar java C:/Users/tanji/Desktop/SoftwareRemodularization/raw_sourcecode/apache-log4j/apache-log4j_7.4.0 ../raw_depends/apache-log4j/apache-log4j_7.4.0\n",
      "cd C:/Users/tanji/Desktop/SoftwareRemodularization/depends-0.9.2 & java -jar depends.jar java C:/Users/tanji/Desktop/SoftwareRemodularization/raw_sourcecode/apache-log4j/apache-log4j_7.3.1 ../raw_depends/apache-log4j/apache-log4j_7.3.1\n",
      "cd C:/Users/tanji/Desktop/SoftwareRemodularization/depends-0.9.2 & java -jar depends.jar java C:/Users/tanji/Desktop/SoftwareRemodularization/raw_sourcecode/apache-log4j/apache-log4j_7.3.0 ../raw_depends/apache-log4j/apache-log4j_7.3.0\n",
      "cd C:/Users/tanji/Desktop/SoftwareRemodularization/depends-0.9.2 & java -jar depends.jar java C:/Users/tanji/Desktop/SoftwareRemodularization/raw_sourcecode/apache-log4j/apache-log4j_7.2.1 ../raw_depends/apache-log4j/apache-log4j_7.2.1\n",
      "cd C:/Users/tanji/Desktop/SoftwareRemodularization/depends-0.9.2 & java -jar depends.jar java C:/Users/tanji/Desktop/SoftwareRemodularization/raw_sourcecode/apache-log4j/apache-log4j_7.2.0 ../raw_depends/apache-log4j/apache-log4j_7.2.0\n",
      "cd C:/Users/tanji/Desktop/SoftwareRemodularization/depends-0.9.2 & java -jar depends.jar java C:/Users/tanji/Desktop/SoftwareRemodularization/raw_sourcecode/apache-log4j/apache-log4j_7.1.0 ../raw_depends/apache-log4j/apache-log4j_7.1.0\n",
      "cd C:/Users/tanji/Desktop/SoftwareRemodularization/depends-0.9.2 & java -jar depends.jar java C:/Users/tanji/Desktop/SoftwareRemodularization/raw_sourcecode/apache-log4j/apache-log4j_6.6.6 ../raw_depends/apache-log4j/apache-log4j_6.6.6\n",
      "cd C:/Users/tanji/Desktop/SoftwareRemodularization/depends-0.9.2 & java -jar depends.jar java C:/Users/tanji/Desktop/SoftwareRemodularization/raw_sourcecode/apache-log4j/apache-log4j_6.6.5 ../raw_depends/apache-log4j/apache-log4j_6.6.5\n",
      "cd C:/Users/tanji/Desktop/SoftwareRemodularization/depends-0.9.2 & java -jar depends.jar java C:/Users/tanji/Desktop/SoftwareRemodularization/raw_sourcecode/apache-log4j/apache-log4j_6.6.4 ../raw_depends/apache-log4j/apache-log4j_6.6.4\n",
      "cd C:/Users/tanji/Desktop/SoftwareRemodularization/depends-0.9.2 & java -jar depends.jar java C:/Users/tanji/Desktop/SoftwareRemodularization/raw_sourcecode/apache-log4j/apache-log4j_6.6.3 ../raw_depends/apache-log4j/apache-log4j_6.6.3\n",
      "cd C:/Users/tanji/Desktop/SoftwareRemodularization/depends-0.9.2 & java -jar depends.jar java C:/Users/tanji/Desktop/SoftwareRemodularization/raw_sourcecode/apache-log4j/apache-log4j_6.6.2 ../raw_depends/apache-log4j/apache-log4j_6.6.2\n",
      "cd C:/Users/tanji/Desktop/SoftwareRemodularization/depends-0.9.2 & java -jar depends.jar java C:/Users/tanji/Desktop/SoftwareRemodularization/raw_sourcecode/apache-log4j/apache-log4j_5.5.5 ../raw_depends/apache-log4j/apache-log4j_5.5.5\n"
     ]
    }
   ],
   "source": [
    "### Run Depends\n",
    "try:\n",
    "    os.mkdir('raw_depends/' + project_name)\n",
    "except:\n",
    "    pass\n",
    "for row in current_project.iterrows():\n",
    "    #command = 'cd C:/Users/tanji/Desktop/SoftwareRemodularization/raw_depends/' + project_name +' & mkdir ' + project_name + '_' +row[1]['version_name']\n",
    "    #os.system(command)\n",
    "    #print(command)\n",
    "    command = 'cd C:/Users/tanji/Desktop/SoftwareRemodularization/depends-0.9.2 & ' + 'java -jar depends.jar java C:/Users/tanji/Desktop/SoftwareRemodularization/raw_sourcecode/'  + project_name + '/' + project_name + '_' + row[1]['version_name']+  ' ../raw_depends/' + project_name + \"/\" + project_name + '_' + row[1]['version_name'] \n",
    "    print(command)\n",
    "    os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/tanji/Desktop/SoftwareRemodularization/raw_depends/apache-log4j/apache-log4j_8.2.0.json\n",
      "C:/Users/tanji/Desktop/SoftwareRemodularization/raw_depends/apache-log4j/apache-log4j_8.1.1.json\n",
      "C:/Users/tanji/Desktop/SoftwareRemodularization/raw_depends/apache-log4j/apache-log4j_8.1.0.json\n",
      "C:/Users/tanji/Desktop/SoftwareRemodularization/raw_depends/apache-log4j/apache-log4j_8.0.0.json\n",
      "C:/Users/tanji/Desktop/SoftwareRemodularization/raw_depends/apache-log4j/apache-log4j_7.7.2.json\n",
      "C:/Users/tanji/Desktop/SoftwareRemodularization/raw_depends/apache-log4j/apache-log4j_7.7.1.json\n",
      "C:/Users/tanji/Desktop/SoftwareRemodularization/raw_depends/apache-log4j/apache-log4j_7.7.0.json\n",
      "C:/Users/tanji/Desktop/SoftwareRemodularization/raw_depends/apache-log4j/apache-log4j_7.6.0.json\n",
      "C:/Users/tanji/Desktop/SoftwareRemodularization/raw_depends/apache-log4j/apache-log4j_7.5.0.json\n",
      "C:/Users/tanji/Desktop/SoftwareRemodularization/raw_depends/apache-log4j/apache-log4j_7.4.0.json\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.mkdir('groundtruth/' + project_name)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.mkdir('MoJo_1.2.1/' + project_name)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "### Counter to only ensure the top 10 projects are selected\n",
    "counter = 10\n",
    "\n",
    "for row in current_project.iterrows():\n",
    "    counter -= 1\n",
    "    if counter < 0:\n",
    "        break\n",
    "    project_rank = row[1]['rank']\n",
    "    version_name = row[1]['version_name']\n",
    "    #print(project_rank)\n",
    "    rootdir = 'C:/Users/tanji/Desktop/SoftwareRemodularization/raw_sourcecode/' + project_name + '/' + project_name + '_' + row[1]['version_name']\n",
    "    \n",
    "    #print(rootdir)\n",
    "    \n",
    "    \n",
    "    ### To obtain the current initial directory\n",
    "    full_dir_arr = []\n",
    "    for root, dirs, files in os.walk(rootdir):\n",
    "        #print(root)\n",
    "        #print(dirs)\n",
    "        for element in files:\n",
    "            if '.java' in element:\n",
    "                dir_string = root + '\\\\' + element\n",
    "                full_dir_arr.append(dir_string)\n",
    "\n",
    "    cluster_dict = {}\n",
    "    cluster_tree = {}\n",
    "\n",
    "\n",
    "    for element in full_dir_arr:\n",
    "        element = element.split('\\\\')\n",
    "        child = element[-1]\n",
    "        parent = element[-2]\n",
    "        cluster_tree[child] = parent\n",
    "            \n",
    "    current_rank = project_rank\n",
    "    while current_rank >= (project_rank - 10):\n",
    "        current_rank -= 1\n",
    "        project_to_be_compared = current_project[current_project['rank'] == current_rank]\n",
    "        project_to_be_compared_rootdir = 'C:/Users/tanji/Desktop/SoftwareRemodularization/raw_sourcecode/' + project_name + '/' + project_name + '_' + project_to_be_compared['version_name'].values[0]\n",
    "        #print(project_to_be_compared_rootdir)\n",
    "\n",
    "\n",
    "        ### To obtain the current initial directory\n",
    "        project_to_be_compared_full_dir_arr = []\n",
    "        for root, dirs, files in os.walk(project_to_be_compared_rootdir):\n",
    "            #print(root)\n",
    "            #print(dirs)\n",
    "            for element in files:\n",
    "                if '.java' in element:\n",
    "                    dir_string = root + '\\\\' + element\n",
    "                    project_to_be_compared_full_dir_arr.append(dir_string)\n",
    "\n",
    "        project_to_be_compared_cluster_dict = {}\n",
    "        project_to_be_compared_cluster_tree = {}\n",
    "\n",
    "\n",
    "        for element in project_to_be_compared_full_dir_arr:\n",
    "            element = element.split('\\\\')\n",
    "            child = element[-1]\n",
    "            parent = element[-2]\n",
    "            project_to_be_compared_cluster_tree[child] = parent\n",
    "                \n",
    "        cluster_tree =  {x:cluster_tree[x] for x in cluster_tree if x in project_to_be_compared_cluster_tree} \n",
    "    \n",
    "    arr_a_rsf = []\n",
    "    filename = 'C:/Users/tanji/Desktop/SoftwareRemodularization/groundtruth/' + project_name + '/' + project_name + '_' + row[1]['version_name'] + '.txt'\n",
    "    with open(filename, 'w') as f:\n",
    "        for key, value in cluster_tree.items():\n",
    "            arr_a_rsf.append(key)\n",
    "            f.write('contain ' + str(value).replace(\" \",'') + ' ' + str(key).replace(' ','') + '\\n')\n",
    "        \n",
    "    depends_dir = 'C:/Users/tanji/Desktop/SoftwareRemodularization/raw_depends/' + project_name + '/' + project_name + '_' + row[1]['version_name'] + '.json'\n",
    "    print(depends_dir)\n",
    "\n",
    "    with open(depends_dir) as f:\n",
    "        depends_results = json.load(f)\n",
    "        index  = 0\n",
    "        var_array = []\n",
    "        for value in depends_results['variables']:\n",
    "            var_array.append([index, value.split('\\\\')[-1]])\n",
    "            #print(index, value)\n",
    "            index += 1\n",
    "\n",
    "        var_df = pd.DataFrame(var_array)\n",
    "        var_df.columns = ['index_val', 'name']\n",
    "\n",
    "        feature_list = {}\n",
    "        feature_index = 2\n",
    "        for element in depends_results['cells']:\n",
    "            #print(element)\n",
    "            try:\n",
    "                for a in element['values']:\n",
    "                    if a not in feature_list:\n",
    "                        feature_list[a] = feature_index\n",
    "                        feature_index += 1\n",
    "                    #print(a['Call'])\n",
    "\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        feature_arr = []\n",
    "        for element in depends_results['cells']:\n",
    "            #print(array)\n",
    "            array = [0] * (len(feature_list) + 2)\n",
    "            values = dict(element['values'])\n",
    "            #print(element)\n",
    "            array[0] = element['src']\n",
    "            array[1] = element['dest']\n",
    "            for feature in feature_list:\n",
    "                try:\n",
    "                    value = values[feature]\n",
    "                    array[feature_list[feature]] = value\n",
    "                except:\n",
    "                    pass\n",
    "            #print(array)\n",
    "            feature_arr.append(array)\n",
    "\n",
    "        feature_df = pd.DataFrame(feature_arr)\n",
    "        col_names = ['src', 'dest']\n",
    "        for element in feature_list:\n",
    "            col_names.append(element)\n",
    "        feature_df.columns = col_names\n",
    "\n",
    "        feature_df['sum'] = feature_df.sum(axis=1) - feature_df['src'] - feature_df['dest']\n",
    "        G = nx.Graph()\n",
    "        for index, row in feature_df.iterrows():\n",
    "            G.add_edge(row['src'], row['dest'], weight=row['sum'])\n",
    "\n",
    "        adj_mat = nx.adjacency_matrix(G)\n",
    "        adj_mat_df = pd.DataFrame(adj_mat.todense())\n",
    "        np.fill_diagonal(adj_mat_df.values, adj_mat_df.values.max())\n",
    "        x = adj_mat_df.values\n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        x_scaled = min_max_scaler.fit_transform(x)\n",
    "        adj_mat_df = pd.DataFrame(x_scaled)\n",
    "        \n",
    "        \n",
    "        n_cluster_divisible_arr = [5,6,7,8,9,10,15,20,25]\n",
    "        affinity_arr = ['euclidean', 'l1', 'l2', 'manhattan', 'cosine']\n",
    "        linkage_arr = ['complete', 'average', 'single']\n",
    "        \n",
    "        n_cluster_divisible_arr = [5, 15]\n",
    "        affinity_arr = ['euclidean']\n",
    "        linkage_arr = ['complete']\n",
    "        \n",
    "        for user_n_cluster in n_cluster_divisible_arr:\n",
    "            for user_affinity in affinity_arr:\n",
    "                for user_linkage in linkage_arr:\n",
    "        \n",
    "                    cluster = AgglomerativeClustering(n_clusters=(len(cluster_tree)//user_n_cluster), affinity=user_affinity, linkage=user_linkage)\n",
    "                    cluster_result = cluster.fit_predict(adj_mat_df)\n",
    "                    \n",
    "                    filename_a = 'C:/Users/tanji/Desktop/SoftwareRemodularization/MoJo_1.2.1/' + project_name + '/' + project_name + '_' + version_name + '_' + str(user_n_cluster) + '_' +str(user_affinity) + '_' + str(user_linkage) + '_a.rsf'\n",
    "                    filename_b = 'C:/Users/tanji/Desktop/SoftwareRemodularization/MoJo_1.2.1/' + project_name + '/' + project_name + '_' + version_name + '_' + str(user_n_cluster) + '_' +str(user_affinity) + '_' + str(user_linkage) + '_b.rsf'\n",
    "                    \n",
    "                    with open(filename_a, 'w') as f:\n",
    "                        for key, value in cluster_tree.items():\n",
    "                            f.write('contain ' + str(value).replace(\" \",'') + ' ' + str(key).replace(' ','') + '\\n')\n",
    "\n",
    "                    arr_b_rsf = []\n",
    "                    with open(filename_b, 'w') as f:\n",
    "                        len_b_rsf = 0\n",
    "                        duplicate_array = []\n",
    "                        for i in range(len(cluster_result)):\n",
    "                            try:\n",
    "                                subject = var_df[var_df['index_val'] == i]['name'].values[0]\n",
    "                                #print(subject)\n",
    "                                #print(subject in cluster_tree)\n",
    "                                if subject in cluster_tree and subject not in duplicate_array:\n",
    "                                    #print(element)\n",
    "                                    duplicate_array.append(subject)\n",
    "                                    string = \"contain \" + str(cluster_result[i]) + \" \" + subject + \"\\n\"\n",
    "                                    arr_b_rsf.append(subject)\n",
    "                                    len_b_rsf += 1\n",
    "                                    f.write(string)\n",
    "                                else:\n",
    "                                    #print(subject)\n",
    "                                    pass\n",
    "                            except:\n",
    "                                pass\n",
    "                    f.close()\n",
    "\n",
    "                    len_a_rsf = len(cluster_tree)\n",
    "\n",
    "                    if len_b_rsf > len_a_rsf:\n",
    "                        rsf_initial_counter = len_a_rsf\n",
    "                        to_be_added = list(set(arr_a_rsf) - set(arr_b_rsf))\n",
    "                        with open(filename_a,'a+') as f:\n",
    "\n",
    "                            for item in to_be_added:\n",
    "                                string = 'contain ' + str(rsf_initial_counter) + \" \" + item + '\\n'\n",
    "                                rsf_initial_counter += 1\n",
    "                                f.write(string)\n",
    "                        f.close()\n",
    "\n",
    "                    elif len_a_rsf > len_b_rsf:\n",
    "            \n",
    "                        rsf_initial_counter = len_b_rsf\n",
    "                        to_be_added = list(set(arr_a_rsf) - set(arr_b_rsf))\n",
    "                        with open(filename_b,'a+') as f:\n",
    "\n",
    "                            for item in to_be_added:\n",
    "                                string = 'contain ' + str(rsf_initial_counter) + \" \" + item + '\\n'\n",
    "                                rsf_initial_counter += 1\n",
    "                                f.write(string)\n",
    "                        f.close()\n",
    "                        \n",
    "                    command = 'cd C:/Users/tanji/Desktop/SoftwareRemodularization/MoJo_1.2.1 & ' + 'java MoJo ' + filename_a + ' ' + filename_b + ' >> ' + project_name + '/' + project_name + '_results.txt'\n",
    "                    #print(command)\n",
    "                    os.system(command)\n",
    "                 \n",
    "                        \n",
    "            \n",
    "        f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncounter = 10\\nfor row in current_project.iterrows():\\n    counter -= 1\\n    if counter < 0:\\n        break\\n    project_rank = row[1][\\'rank\\']\\n    #print(project_rank)\\n    depends_dir = \\'C:/Users/tanji/Desktop/SoftwareRemodularization/raw_depends/\\' + project_name + \\'/\\' + project_name + \\'_\\' + row[1][\\'version_name\\'] + \\'.json\\'\\n    #print(depends_dir)\\n\\n    with open(depends_dir) as f:\\n        depends_results = json.load(f)\\n        index  = 0\\n        var_array = []\\n        for value in depends_results[\\'variables\\']:\\n            var_array.append([index, value.split(\\'\\\\\\')[-1]])\\n            #print(index, value)\\n            index += 1\\n\\n        var_df = pd.DataFrame(var_array)\\n        var_df.columns = [\\'index_val\\', \\'name\\']\\n\\n        feature_list = {}\\n        feature_index = 2\\n        for element in depends_results[\\'cells\\']:\\n            #print(element)\\n            try:\\n                for a in element[\\'values\\']:\\n                    if a not in feature_list:\\n                        feature_list[a] = feature_index\\n                        feature_index += 1\\n                    #print(a[\\'Call\\'])\\n\\n\\n            except:\\n                pass\\n\\n        feature_arr = []\\n        for element in depends_results[\\'cells\\']:\\n            #print(array)\\n            array = [0] * (len(feature_list) + 2)\\n            values = dict(element[\\'values\\'])\\n            #print(element)\\n            array[0] = element[\\'src\\']\\n            array[1] = element[\\'dest\\']\\n            for feature in feature_list:\\n                try:\\n                    value = values[feature]\\n                    array[feature_list[feature]] = value\\n                except:\\n                    pass\\n            #print(array)\\n            feature_arr.append(array)\\n\\n        feature_df = pd.DataFrame(feature_arr)\\n        col_names = [\\'src\\', \\'dest\\']\\n        for element in feature_list:\\n            col_names.append(element)\\n        feature_df.columns = col_names\\n\\n        feature_df[\\'sum\\'] = feature_df.sum(axis=1) - feature_df[\\'src\\'] - feature_df[\\'dest\\']\\n        G = nx.Graph()\\n        for index, row in feature_df.iterrows():\\n            G.add_edge(row[\\'src\\'], row[\\'dest\\'], weight=row[\\'sum\\'])\\n\\n        adj_mat = nx.adjacency_matrix(G)\\n        adj_mat_df = pd.DataFrame(adj_mat.todense())\\n        np.fill_diagonal(adj_mat_df.values, adj_mat_df.values.max())\\n        x = adj_mat_df.values\\n        min_max_scaler = preprocessing.MinMaxScaler()\\n        x_scaled = min_max_scaler.fit_transform(x)\\n        adj_mat_df = pd.DataFrame(x_scaled)\\n        \\n        \\n        n_cluster_divisible_arr = [5,6,7,8,9,10,11,12,13,14,15]\\n        affinity_arr = [\\'euclidean\\', \\'l1\\', \\'l2\\', \\'manhattan\\', \\'cosine\\']\\n        linkage_arr = [\\'complete\\', \\'average\\', \\'single\\']\\n        \\n        for user_n_cluster in n_cluster_divisible_arr:\\n            for user_affinity in affinity_arr:\\n                for user_linkage in linkage_arr:\\n        \\n                    cluster = AgglomerativeClustering(n_clusters=user_n_cluster, affinity=user_affinity, linkage=user_linkage)\\n                    cluster_result = cluster.fit_predict(adj_mat_df)\\n                    \\n                    filename_a = \\'C:/Users/tanji/Desktop/SoftwareRemodularization/MoJo_1.2.1/\\' + project_name + \\'/\\' + project_name + \\'_\\' + version_name + \\'_\\' + str(user_n_cluster) + \\'_\\' +str(user_affinity) + \\'_\\' + str(user_linkage) + \\'_a.rsf\\'\\n                    filename_b = \\'C:/Users/tanji/Desktop/SoftwareRemodularization/MoJo_1.2.1/\\' + project_name + \\'/\\' + project_name + \\'_\\' + version_name + \\'_\\' + str(user_n_cluster) + \\'_\\' +str(user_affinity) + \\'_\\' + str(user_linkage) + \\'_b.rsf\\'\\n                    with open(\\'test_b.rsf\\', \\'w\\') as f:\\n                        len_b_rsf = 0\\n                        duplicate_array = []\\n                        for i in range(len(cluster_result)):\\n                            try:\\n                                subject = var_df[var_df[\\'index_val\\'] == i][\\'name\\'].values[0]\\n                                #print(subject)\\n                                #print(subject in cluster_tree)\\n                                if subject in cluster_tree and subject not in duplicate_array:\\n                                    #print(element)\\n                                    duplicate_array.append(subject)\\n                                    string = \"contain \" + str(cluster_result[i]) + \" \" + subject + \"\\n\"\\n                                    arr_b_rsf.append(subject)\\n                                    len_b_rsf += 1\\n                                    f.write(string)\\n                                else:\\n                                    print(subject)\\n                            except:\\n                                pass\\n                    f.close()\\n\\n                    len_a_rsf = len(cluster_tree)\\n\\n                    if len_b_rsf > len_a_rsf:\\n                        rsf_initial_counter = len_a_rsf\\n                        to_be_added = list(set(arr_a_rsf) - set(arr_b_rsf))\\n                        with open(\\'test_a.rsf\\',\\'a+\\') as f:\\n\\n                            for item in to_be_added:\\n                                string = \\'contain \\' + str(rsf_initial_counter) + \" \" + item + \\'\\n\\'\\n                                rsf_initial_counter += 1\\n                                f.write(string)\\n                        f.close()\\n\\n                    elif len_a_rsf > len_b_rsf:\\n                        print(\\'here\\')\\n                        rsf_initial_counter = len_b_rsf\\n                        to_be_added = list(set(arr_a_rsf) - set(arr_b_rsf))\\n                        with open(\\'test_b.rsf\\',\\'a+\\') as f:\\n\\n                            for item in to_be_added:\\n                                string = \\'contain \\' + str(rsf_initial_counter) + \" \" + item + \\'\\n\\'\\n                                rsf_initial_counter += 1\\n                                f.write(string)\\n                        f.close()\\n        \\n        \\n        \\n        f.close()\\n        \\n        \\n        \\n        \\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "counter = 10\n",
    "for row in current_project.iterrows():\n",
    "    counter -= 1\n",
    "    if counter < 0:\n",
    "        break\n",
    "    project_rank = row[1]['rank']\n",
    "    #print(project_rank)\n",
    "    depends_dir = 'C:/Users/tanji/Desktop/SoftwareRemodularization/raw_depends/' + project_name + '/' + project_name + '_' + row[1]['version_name'] + '.json'\n",
    "    #print(depends_dir)\n",
    "\n",
    "    with open(depends_dir) as f:\n",
    "        depends_results = json.load(f)\n",
    "        index  = 0\n",
    "        var_array = []\n",
    "        for value in depends_results['variables']:\n",
    "            var_array.append([index, value.split('\\\\')[-1]])\n",
    "            #print(index, value)\n",
    "            index += 1\n",
    "\n",
    "        var_df = pd.DataFrame(var_array)\n",
    "        var_df.columns = ['index_val', 'name']\n",
    "\n",
    "        feature_list = {}\n",
    "        feature_index = 2\n",
    "        for element in depends_results['cells']:\n",
    "            #print(element)\n",
    "            try:\n",
    "                for a in element['values']:\n",
    "                    if a not in feature_list:\n",
    "                        feature_list[a] = feature_index\n",
    "                        feature_index += 1\n",
    "                    #print(a['Call'])\n",
    "\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        feature_arr = []\n",
    "        for element in depends_results['cells']:\n",
    "            #print(array)\n",
    "            array = [0] * (len(feature_list) + 2)\n",
    "            values = dict(element['values'])\n",
    "            #print(element)\n",
    "            array[0] = element['src']\n",
    "            array[1] = element['dest']\n",
    "            for feature in feature_list:\n",
    "                try:\n",
    "                    value = values[feature]\n",
    "                    array[feature_list[feature]] = value\n",
    "                except:\n",
    "                    pass\n",
    "            #print(array)\n",
    "            feature_arr.append(array)\n",
    "\n",
    "        feature_df = pd.DataFrame(feature_arr)\n",
    "        col_names = ['src', 'dest']\n",
    "        for element in feature_list:\n",
    "            col_names.append(element)\n",
    "        feature_df.columns = col_names\n",
    "\n",
    "        feature_df['sum'] = feature_df.sum(axis=1) - feature_df['src'] - feature_df['dest']\n",
    "        G = nx.Graph()\n",
    "        for index, row in feature_df.iterrows():\n",
    "            G.add_edge(row['src'], row['dest'], weight=row['sum'])\n",
    "\n",
    "        adj_mat = nx.adjacency_matrix(G)\n",
    "        adj_mat_df = pd.DataFrame(adj_mat.todense())\n",
    "        np.fill_diagonal(adj_mat_df.values, adj_mat_df.values.max())\n",
    "        x = adj_mat_df.values\n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        x_scaled = min_max_scaler.fit_transform(x)\n",
    "        adj_mat_df = pd.DataFrame(x_scaled)\n",
    "        \n",
    "        \n",
    "        n_cluster_divisible_arr = [5,6,7,8,9,10,11,12,13,14,15]\n",
    "        affinity_arr = ['euclidean', 'l1', 'l2', 'manhattan', 'cosine']\n",
    "        linkage_arr = ['complete', 'average', 'single']\n",
    "        \n",
    "        for user_n_cluster in n_cluster_divisible_arr:\n",
    "            for user_affinity in affinity_arr:\n",
    "                for user_linkage in linkage_arr:\n",
    "        \n",
    "                    cluster = AgglomerativeClustering(n_clusters=user_n_cluster, affinity=user_affinity, linkage=user_linkage)\n",
    "                    cluster_result = cluster.fit_predict(adj_mat_df)\n",
    "                    \n",
    "                    filename_a = 'C:/Users/tanji/Desktop/SoftwareRemodularization/MoJo_1.2.1/' + project_name + '/' + project_name + '_' + version_name + '_' + str(user_n_cluster) + '_' +str(user_affinity) + '_' + str(user_linkage) + '_a.rsf'\n",
    "                    filename_b = 'C:/Users/tanji/Desktop/SoftwareRemodularization/MoJo_1.2.1/' + project_name + '/' + project_name + '_' + version_name + '_' + str(user_n_cluster) + '_' +str(user_affinity) + '_' + str(user_linkage) + '_b.rsf'\n",
    "                    with open('test_b.rsf', 'w') as f:\n",
    "                        len_b_rsf = 0\n",
    "                        duplicate_array = []\n",
    "                        for i in range(len(cluster_result)):\n",
    "                            try:\n",
    "                                subject = var_df[var_df['index_val'] == i]['name'].values[0]\n",
    "                                #print(subject)\n",
    "                                #print(subject in cluster_tree)\n",
    "                                if subject in cluster_tree and subject not in duplicate_array:\n",
    "                                    #print(element)\n",
    "                                    duplicate_array.append(subject)\n",
    "                                    string = \"contain \" + str(cluster_result[i]) + \" \" + subject + \"\\n\"\n",
    "                                    arr_b_rsf.append(subject)\n",
    "                                    len_b_rsf += 1\n",
    "                                    f.write(string)\n",
    "                                else:\n",
    "                                    print(subject)\n",
    "                            except:\n",
    "                                pass\n",
    "                    f.close()\n",
    "\n",
    "                    len_a_rsf = len(cluster_tree)\n",
    "\n",
    "                    if len_b_rsf > len_a_rsf:\n",
    "                        rsf_initial_counter = len_a_rsf\n",
    "                        to_be_added = list(set(arr_a_rsf) - set(arr_b_rsf))\n",
    "                        with open('test_a.rsf','a+') as f:\n",
    "\n",
    "                            for item in to_be_added:\n",
    "                                string = 'contain ' + str(rsf_initial_counter) + \" \" + item + '\\n'\n",
    "                                rsf_initial_counter += 1\n",
    "                                f.write(string)\n",
    "                        f.close()\n",
    "\n",
    "                    elif len_a_rsf > len_b_rsf:\n",
    "                        print('here')\n",
    "                        rsf_initial_counter = len_b_rsf\n",
    "                        to_be_added = list(set(arr_a_rsf) - set(arr_b_rsf))\n",
    "                        with open('test_b.rsf','a+') as f:\n",
    "\n",
    "                            for item in to_be_added:\n",
    "                                string = 'contain ' + str(rsf_initial_counter) + \" \" + item + '\\n'\n",
    "                                rsf_initial_counter += 1\n",
    "                                f.write(string)\n",
    "                        f.close()\n",
    "        \n",
    "        \n",
    "        \n",
    "        f.close()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\"\"\"    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "index  = 0\n",
    "var_array = []\n",
    "for value in depends_results['variables']:\n",
    "    var_array.append([index, value.split('\\\\')[-1]])\n",
    "    #print(index, value)\n",
    "    index += 1\n",
    "\n",
    "var_df = pd.DataFrame(var_array)\n",
    "var_df.columns = ['index_val', 'name']\n",
    "\n",
    "feature_list = {}\n",
    "feature_index = 2\n",
    "for element in depends_results['cells']:\n",
    "    #print(element)\n",
    "    try:\n",
    "        for a in element['values']:\n",
    "            if a not in feature_list:\n",
    "                feature_list[a] = feature_index\n",
    "                feature_index += 1\n",
    "            #print(a['Call'])\n",
    "\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "feature_arr = []\n",
    "for element in depends_results['cells']:\n",
    "    #print(array)\n",
    "    array = [0] * (len(feature_list) + 2)\n",
    "    values = dict(element['values'])\n",
    "    #print(element)\n",
    "    array[0] = element['src']\n",
    "    array[1] = element['dest']\n",
    "    for feature in feature_list:\n",
    "        try:\n",
    "            value = values[feature]\n",
    "            array[feature_list[feature]] = value\n",
    "        except:\n",
    "            pass\n",
    "    #print(array)\n",
    "    feature_arr.append(array)\n",
    "\n",
    "feature_df = pd.DataFrame(feature_arr)\n",
    "col_names = ['src', 'dest']\n",
    "for element in feature_list:\n",
    "    col_names.append(element)\n",
    "feature_df.columns = col_names\n",
    "\n",
    "feature_df['sum'] = feature_df.sum(axis=1) - feature_df['src'] - feature_df['dest']\n",
    "G = nx.Graph()\n",
    "for index, row in feature_df.iterrows():\n",
    "    G.add_edge(row['src'], row['dest'], weight=row['sum'])\n",
    "\n",
    "adj_mat = nx.adjacency_matrix(G)\n",
    "adj_mat_df = pd.DataFrame(adj_mat.todense())\n",
    "np.fill_diagonal(adj_mat_df.values, adj_mat_df.values.max())\n",
    "x = adj_mat_df.values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "adj_mat_df = pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_df.head()\n",
    "#for row in var_df.iterrows():\n",
    "    #print(row[1]['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(var_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = AgglomerativeClustering(n_clusters=30, affinity='euclidean', linkage='complete')\n",
    "cluster_result = cluster.fit_predict(adj_mat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(cluster_result))\n",
    "cluster_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8//3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_b.rsf', 'w') as f:\n",
    "    len_b_rsf = 0\n",
    "    duplicate_array = []\n",
    "    for i in range(len(cluster_result)):\n",
    "        try:\n",
    "            subject = var_df[var_df['index_val'] == i]['name'].values[0]\n",
    "            #print(subject)\n",
    "            #print(subject in cluster_tree)\n",
    "            if subject in cluster_tree and subject not in duplicate_array:\n",
    "                #print(element)\n",
    "                duplicate_array.append(subject)\n",
    "                string = \"contain \" + str(cluster_result[i]) + \" \" + subject + \"\\n\"\n",
    "                arr_b_rsf.append(subject)\n",
    "                len_b_rsf += 1\n",
    "                f.write(string)\n",
    "            else:\n",
    "                print(subject)\n",
    "        except:\n",
    "            pass\n",
    "    f.close()\n",
    "\n",
    "len_a_rsf = len(cluster_tree)\n",
    "\n",
    "if len_b_rsf > len_a_rsf:\n",
    "    rsf_initial_counter = len_a_rsf\n",
    "    to_be_added = list(set(arr_a_rsf) - set(arr_b_rsf))\n",
    "    with open('test_a.rsf','a+') as f:\n",
    "        \n",
    "        for item in to_be_added:\n",
    "            string = 'contain ' + str(rsf_initial_counter) + \" \" + item + '\\n'\n",
    "            rsf_initial_counter += 1\n",
    "            f.write(string)\n",
    "    f.close()\n",
    "        \n",
    "elif len_a_rsf > len_b_rsf:\n",
    "    print('here')\n",
    "    rsf_initial_counter = len_b_rsf\n",
    "    to_be_added = list(set(arr_a_rsf) - set(arr_b_rsf))\n",
    "    with open('test_b.rsf','a+') as f:\n",
    "        \n",
    "        for item in to_be_added:\n",
    "            string = 'contain ' + str(rsf_initial_counter) + \" \" + item + '\\n'\n",
    "            rsf_initial_counter += 1\n",
    "            f.write(string)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'AppenderTable.java' in cluster_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cluster_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_a_rsf = []\n",
    "arr_b_rsf = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for key in cluster_tree:\n",
    "    arr_a_rsf.append(key)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(test_arr_1) - set(test_arr_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arr_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
